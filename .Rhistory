data = as.data.frame(pollen), dist = "MN"))
fit_dm  <- suppressWarnings(MGLMreg(cbind(Pinus, Abies, Quercus, Alnus) ~ 1,
data = as.data.frame(pollen), dist = "DM"))
## 3) fit fixed‐effects MLN
fit_mln <- FMLN(
Y              = Y,
X              = X,
n_iter         = n_iter,
burn_in        = burn_in,
thin           = thin,
proposal       = proposal,
verbose        = TRUE
)
## 4) prepare predictive replicates
# 4a) MN model: draw P full-dataset replicates
probs_mlr <- fit_mlr@fitted
Y_pred_mlr <- vector("list", P)
for (p_i in seq_len(P)) {
M <- t(sapply(seq_len(N),
function(i) rmultinom(1, size = PA[i], prob = probs_mlr[i, ])))
Y_pred_mlr[[p_i]] <- M
}
# 4b) DM model: draw P replicates with Dirichlet‐multinomial
alpha_hat <- exp(fit_dm@coefficients)
Y_pred_dm <- vector("list", P)
for (p_i in seq_len(P)) {
M <- t(sapply(seq_len(N),
function(i) MGLM::rdirmn(n    = 1,
size = PA[i],
alpha = alpha_hat)))
Y_pred_dm[[p_i]] <- M
}
# 4c) MLN model: use posterior‐mean β and Σ to draw P replicates
# posterior means:
beta_arr  <- simplify2array(fit_mln$beta_chain)    # p × d × n_saves
Sigma_arr <- simplify2array(fit_mln$sigma_chain)   # d × d × n_saves
beta_mean  <- apply(beta_arr,  c(1,2), mean)
Sigma_mean <- apply(Sigma_arr, c(1,2), mean)
Y_pred_mln <- vector("list", P)
for (p_i in seq_len(P)) {
Y_pred_mln[[p_i]] <- sample_posterior_predictive(
X     = X,
beta  = beta_mean,
Sigma = Sigma_mean,
PA    = PA,
mixed = FALSE
)
}
## 5) compute Mahalanobis‐residuals
resids_mlr <- MDres(Y, Y_pred_mlr)
print('\n')
resids_dm  <- MDres(Y, Y_pred_dm)
print('\n')
resids_mln <- MDres(Y, Y_pred_mln)
## return all results
output = list(
fit_mlr    = fit_mlr,
fit_dm     = fit_dm,
fit_mln    = fit_mln,
Y_pred_mlr = Y_pred_mlr,
Y_pred_dm  = Y_pred_dm,
Y_pred_mln = Y_pred_mln,
resids_mlr = resids_mlr,
resids_dm  = resids_dm,
resids_mln = resids_mln
)
return(output)
}
test_run <- run_pollen_models()
#'
#' @return Numeric vector of length N of residuals (class 'mdres').
#'
#' @examples
#' \dontrun{
#' resids <- MDres(Y_obs, Y_pred_list)
#' summary(resids)
#' }
#'
#' @export
MDres <- function(Y, Y_pred_list) {
Y_obs <- compress_counts(Y)
alr_obs <- alr(Y_obs)
N <- nrow(Y_obs)
d <- ncol(Y_obs) - 1
P <- length(Y_pred_list)
pred_array <- array(NA, dim = c(N, d, P))
for (j in seq_len(P)) {
pred_array[,,j] <- alr(compress_counts(Y_pred_list[[j]]))
}
mu_all <- apply(pred_array, 1:2, mean)
Sigma_all <- lapply(seq_len(N), function(i) cov(t(pred_array[i,,])))
mds_list <- vector("list", N)
if (interactive()) cat("Computing Mahalanobis distances:\n")
start_time <- Sys.time()
for (i in seq_len(N)) {
if (interactive() && (i %% max(1, floor(N / 100)) == 0 || i == N)) {
pct <- floor(100 * i / N)
elapsed <- Sys.time() - start_time
eta <- (as.numeric(elapsed) / i) * (N - i)
cat(sprintf("\r[%3d%%] ETA: %s\n", pct, format(.POSIXct(eta, tz="GMT"), "%M:%S")))
flush.console()
}
pred_i <- t(pred_array[i,,])
w_obs_i <- alr_obs[i, ]
obsi <- rbind(w_obs_i, pred_i)
mds_list[[i]] <- apply(obsi, 1, mahalanobis, center = mu_all[i,], cov = Sigma_all[[i]])
}
u_resids <- vapply(seq_len(N), function(i) {
obs_val <- mds_list[[i]][1]
post_vals <- mds_list[[i]][-1]
ecdf_i <- ecdf(post_vals)
if (obs_val <= min(post_vals)) {
minpct <- 0
maxpct <- ecdf_i(min(post_vals))
if (maxpct == 0) maxpct <- (length(post_vals) - 1) / length(post_vals)
} else if (obs_val > max(post_vals)) {
minpct <- ecdf_i(max(post_vals))
maxpct <- 1
if (minpct == 1) minpct <- (length(post_vals) - 1) / length(post_vals)
} else {
sorted_vals <- sort(post_vals)
lower <- max(which(sorted_vals < obs_val))
minpct <- ecdf_i(sorted_vals[lower])
maxpct <- ecdf_i(obs_val)
if (minpct == 1) minpct <- (length(post_vals) - 1) / length(post_vals)
if (maxpct == 0) maxpct <- (length(post_vals) - 1) / length(post_vals)
}
runif(1, minpct, maxpct)
}, numeric(1))
z_resids <- qnorm(u_resids)
class(z_resids) <- "mdres"
return(z_resids)
}
test_run <- run_pollen_models()
#'
#' @return Numeric vector of length N of residuals (class 'mdres').
#'
#' @examples
#' \dontrun{
#' resids <- MDres(Y_obs, Y_pred_list)
#' summary(resids)
#' }
#'
#' @export
MDres <- function(Y, Y_pred_list) {
Y_obs <- compress_counts(Y)
alr_obs <- alr(Y_obs)
N <- nrow(Y_obs)
d <- ncol(Y_obs) - 1
P <- length(Y_pred_list)
pred_array <- array(NA, dim = c(N, d, P))
for (j in seq_len(P)) {
pred_array[,,j] <- alr(compress_counts(Y_pred_list[[j]]))
}
mu_all <- apply(pred_array, 1:2, mean)
Sigma_all <- lapply(seq_len(N), function(i) cov(t(pred_array[i,,])))
mds_list <- vector("list", N)
if (interactive()) cat("Computing Mahalanobis distances:\n")
start_time <- Sys.time()
for (i in seq_len(N)) {
if (interactive() && (i %% max(1, floor(N / 100)) == 0 || i == N)) {
pct <- floor(100 * i / N)
elapsed <- Sys.time() - start_time
eta <- (as.numeric(elapsed) / i) * (N - i)
cat(sprintf("\r[%3d%%] ETA: %s", pct, format(.POSIXct(eta, tz="GMT"), "%M:%S")))
flush.console()
}
pred_i <- t(pred_array[i,,])
w_obs_i <- alr_obs[i, ]
obsi <- rbind(w_obs_i, pred_i)
mds_list[[i]] <- apply(obsi, 1, mahalanobis, center = mu_all[i,], cov = Sigma_all[[i]])
}
u_resids <- vapply(seq_len(N), function(i) {
obs_val <- mds_list[[i]][1]
post_vals <- mds_list[[i]][-1]
ecdf_i <- ecdf(post_vals)
if (obs_val <= min(post_vals)) {
minpct <- 0
maxpct <- ecdf_i(min(post_vals))
if (maxpct == 0) maxpct <- (length(post_vals) - 1) / length(post_vals)
} else if (obs_val > max(post_vals)) {
minpct <- ecdf_i(max(post_vals))
maxpct <- 1
if (minpct == 1) minpct <- (length(post_vals) - 1) / length(post_vals)
} else {
sorted_vals <- sort(post_vals)
lower <- max(which(sorted_vals < obs_val))
minpct <- ecdf_i(sorted_vals[lower])
maxpct <- ecdf_i(obs_val)
if (minpct == 1) minpct <- (length(post_vals) - 1) / length(post_vals)
if (maxpct == 0) maxpct <- (length(post_vals) - 1) / length(post_vals)
}
runif(1, minpct, maxpct)
}, numeric(1))
z_resids <- qnorm(u_resids)
class(z_resids) <- "mdres"
return(z_resids)
}
test_run <- run_pollen_models()
#’ summary(pollen_res$resids_dm)
#’ summary(pollen_res$resids_mln)
#’ }
#’
#’ @importFrom stats rmultinom
#’ @importFrom dirmult rdirmn
#’ @importFrom mvnfast rmvn
#’ @importFrom utils txtProgressBar setTxtProgressBar flush.console
#’ @importFrom MGLM MGLMreg
#’ @export
run_pollen_models <- function(n_iter   = 1000,
burn_in  = 400,
thin     = 2,
proposal = "normbeta",
P        = 1000) {
## dependencies
if (!requireNamespace("MM",   quietly = TRUE)) stop("Install the 'MM' package to load pollen data")
if (!requireNamespace("MGLM", quietly = TRUE)) stop("Install the 'MGLM' package for MGLMreg()")
## 1) load data
data(pollen, package = "MM")
Y  <- as.matrix(pollen)
N  <- nrow(Y)
PA <- rowSums(Y)
J  <- ncol(Y)
X <- matrix(1, nrow = N, ncol = 1)  # intercept‐only design
## 2) fit M-Logit (multinomial) and Dirichlet-multinomial via MGLM
fit_mlr <- suppressWarnings(MGLMreg(cbind(Pinus, Abies, Quercus, Alnus) ~ 1,
data = as.data.frame(pollen), dist = "MN"))
fit_dm  <- suppressWarnings(MGLMreg(cbind(Pinus, Abies, Quercus, Alnus) ~ 1,
data = as.data.frame(pollen), dist = "DM"))
## 3) fit fixed‐effects MLN
fit_mln <- FMLN(
Y              = Y,
X              = X,
n_iter         = n_iter,
burn_in        = burn_in,
thin           = thin,
proposal       = proposal,
verbose        = TRUE
)
## 4) prepare predictive replicates
# 4a) MN model: draw P full-dataset replicates
probs_mlr <- fit_mlr@fitted
Y_pred_mlr <- vector("list", P)
for (p_i in seq_len(P)) {
M <- t(sapply(seq_len(N),
function(i) rmultinom(1, size = PA[i], prob = probs_mlr[i, ])))
Y_pred_mlr[[p_i]] <- M
}
# 4b) DM model: draw P replicates with Dirichlet‐multinomial
alpha_hat <- exp(fit_dm@coefficients)
Y_pred_dm <- vector("list", P)
for (p_i in seq_len(P)) {
M <- t(sapply(seq_len(N),
function(i) MGLM::rdirmn(n    = 1,
size = PA[i],
alpha = alpha_hat)))
Y_pred_dm[[p_i]] <- M
}
# 4c) MLN model: use posterior‐mean β and Σ to draw P replicates
# posterior means:
beta_arr  <- simplify2array(fit_mln$beta_chain)    # p × d × n_saves
Sigma_arr <- simplify2array(fit_mln$sigma_chain)   # d × d × n_saves
beta_mean  <- apply(beta_arr,  c(1,2), mean)
Sigma_mean <- apply(Sigma_arr, c(1,2), mean)
Y_pred_mln <- vector("list", P)
for (p_i in seq_len(P)) {
Y_pred_mln[[p_i]] <- sample_posterior_predictive(
X     = X,
beta  = beta_mean,
Sigma = Sigma_mean,
PA    = PA,
mixed = FALSE
)
}
## 5) compute Mahalanobis‐residuals
cat("\n")  # ensure we start on a fresh line
message("▶ Computing MDRes for multinomial‐logit model")
resids_mlr <- MDres(Y, Y_pred_mlr)
cat("\n")  # ensure we start on a fresh line
message("▶ Computing MDRes for Dirichlet-multinomial model")
resids_dm  <- MDres(Y, Y_pred_dm)
cat("\n")  # ensure we start on a fresh line
message("▶ Computing MDRes for multinomial‐logistic-normal model")
resids_mln <- MDres(Y, Y_pred_mln)
## return all results
output = list(
fit_mlr    = fit_mlr,
fit_dm     = fit_dm,
fit_mln    = fit_mln,
Y_pred_mlr = Y_pred_mlr,
Y_pred_dm  = Y_pred_dm,
Y_pred_mln = Y_pred_mln,
resids_mlr = resids_mlr,
resids_dm  = resids_dm,
resids_mln = resids_mln
)
return(output)
}
test_run <- run_pollen_models()
#’ summary(pollen_res$resids_dm)
#’ summary(pollen_res$resids_mln)
#’ }
#’
#’ @importFrom stats rmultinom
#’ @importFrom dirmult rdirmn
#’ @importFrom mvnfast rmvn
#’ @importFrom utils txtProgressBar setTxtProgressBar flush.console
#’ @importFrom MGLM MGLMreg
#’ @export
run_pollen_models <- function(n_iter   = 1000,
burn_in  = 400,
thin     = 2,
proposal = "normbeta",
P        = 1000) {
## dependencies
if (!requireNamespace("MM",   quietly = TRUE)) stop("Install the 'MM' package to load pollen data")
if (!requireNamespace("MGLM", quietly = TRUE)) stop("Install the 'MGLM' package for MGLMreg()")
## 1) load data
data(pollen, package = "MM")
Y  <- as.matrix(pollen)
N  <- nrow(Y)
PA <- rowSums(Y)
J  <- ncol(Y)
X <- matrix(1, nrow = N, ncol = 1)  # intercept‐only design
## 2) fit M-Logit (multinomial) and Dirichlet-multinomial via MGLM
message("▶ Fitting multinomial-logistic model using MGLMreg()")
fit_mlr <- suppressWarnings(MGLMreg(cbind(Pinus, Abies, Quercus, Alnus) ~ 1,
data = as.data.frame(pollen), dist = "MN"))
cat("Done: \n")
message("▶ Fitting Dirichlet-lmultinomial model using MGLMreg()")
fit_dm  <- suppressWarnings(MGLMreg(cbind(Pinus, Abies, Quercus, Alnus) ~ 1,
data = as.data.frame(pollen), dist = "DM"))
## 3) fit fixed‐effects MLN
cat("Done: \n")
message("▶ Fitting multinomial-logistic-normal model using FMLN()")
fit_mln <- FMLN(
Y              = Y,
X              = X,
n_iter         = n_iter,
burn_in        = burn_in,
thin           = thin,
proposal       = proposal,
verbose        = TRUE
)
## 4) prepare predictive replicates
cat("Done: \n ")
message("▶ Drawing sampling distributions of predicted values from each model")
# 4a) MN model: draw P full-dataset replicates
probs_mlr <- fit_mlr@fitted
Y_pred_mlr <- vector("list", P)
for (p_i in seq_len(P)) {
M <- t(sapply(seq_len(N),
function(i) rmultinom(1, size = PA[i], prob = probs_mlr[i, ])))
Y_pred_mlr[[p_i]] <- M
}
# 4b) DM model: draw P replicates with Dirichlet‐multinomial
alpha_hat <- exp(fit_dm@coefficients)
Y_pred_dm <- vector("list", P)
for (p_i in seq_len(P)) {
M <- t(sapply(seq_len(N),
function(i) MGLM::rdirmn(n    = 1,
size = PA[i],
alpha = alpha_hat)))
Y_pred_dm[[p_i]] <- M
}
# 4c) MLN model: use posterior‐mean β and Σ to draw P replicates
# posterior means:
beta_arr  <- simplify2array(fit_mln$beta_chain)    # p × d × n_saves
Sigma_arr <- simplify2array(fit_mln$sigma_chain)   # d × d × n_saves
beta_mean  <- apply(beta_arr,  c(1,2), mean)
Sigma_mean <- apply(Sigma_arr, c(1,2), mean)
Y_pred_mln <- vector("list", P)
for (p_i in seq_len(P)) {
Y_pred_mln[[p_i]] <- sample_posterior_predictive(
X     = X,
beta  = beta_mean,
Sigma = Sigma_mean,
PA    = PA,
mixed = FALSE
)
}
## 5) compute Mahalanobis‐residuals
cat("Done: \n ")  # ensure we start on a fresh line
message("▶ Computing MDRes for multinomial‐logit model")
resids_mlr <- MDres(Y, Y_pred_mlr)
cat("Done: \n")  # ensure we start on a fresh line
message("▶ Computing MDRes for Dirichlet-multinomial model")
resids_dm  <- MDres(Y, Y_pred_dm)
cat("Done: \n")  # ensure we start on a fresh line
message("▶ Computing MDRes for multinomial‐logistic-normal model")
resids_mln <- MDres(Y, Y_pred_mln)
## return all results
output = list(
fit_mlr    = fit_mlr,
fit_dm     = fit_dm,
fit_mln    = fit_mln,
Y_pred_mlr = Y_pred_mlr,
Y_pred_dm  = Y_pred_dm,
Y_pred_mln = Y_pred_mln,
resids_mlr = resids_mlr,
resids_dm  = resids_dm,
resids_mln = resids_mln
)
return(output)
}
test_run <- run_pollen_models()
summary(test_run$resids_mlr)
summary(test_run$resids_dm)
summary(test_run$resids_mln)
devtools::document()
getwd()
install.packages('tidymodels')
install.packages("tidymodels")
library(tidymodels)  # For data splitting
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
# Diagnostics and plotting
library(car)          # for qqPlot with confidence envelopes
library(EnvStats)     # for uniform qqPlot
# Parallel processing
library(doParallel)   # for parallel computing
library(iterators)    # helper functions for parallel loops
# Multinomial and distributional tools
library(dirmult)      # estimates Dirichlet parameters
library(MCMCpack)     # inverse Wishart sampling
library(MGLM)         # multinomial logistic regression with counts
library(mvnfast)      # fast multivariate normal sampling
# Data manipulation
library(tidyr)
library(dplyr)
# Load fitted multinomial GAMM results
GDuM_FOD_sex <- readRDS(
"GDuM_FOD_SEX_result_TOTAL_NAS_4FOD_3m_7_24_2025.rds"
)
library(MMLN)
library(MMLN)
# 1. Simulate a small mixed-effects dataset
set.seed(42)
sim <- simulate_mixed_mln_data(
m       = 10,          # 10 groups
n_i     = 10,          # 10 observations per group
p       = 3,           # 3 fixed covariates (incl. intercept)
d       = 2,           # 3 outcome categories
beta    = matrix(c(0.5, -1, 0.2, 0.3, 0.7, -0.4), 3, 2),
Sigma   = diag(2),
Phi     = 5*diag(2),
n_mean = 200
)
?simulate_mixed_mln_data
library(MMLN)
# 1. Simulate a small mixed-effects dataset
set.seed(42)
sim <- simulate_mixed_mln_data(
m       = 10,          # 10 groups
n_i     = 10,          # 10 observations per group
p       = 3,           # 3 fixed covariates (incl. intercept)
d       = 2,           # 3 outcome categories
beta    = matrix(c(0.5, -1, 0.2, 0.3, 0.7, -0.4), 3, 2),
Sigma   = diag(2),
Phi     = 5*diag(2),
PA_mean = 200
)
# 2. Fit a fixed-effects MLN model
res_f <- FMLN(
Y            = sim$Y,
X            = sim$X,
n_iter       = 1000,
burn_in      = 300,
thin         = 2,
proposal     = "normbeta",
verbose      = TRUE
)
# 3. Fit a mixed-effects MLN model
res_m <- MMLN(
Y            = sim$Y,
X            = sim$X,
Z            = sim$Z,
n_iter       = 1000,
burn_in      = 300,
thin         = 2,
proposal     = "normbeta",
verbose      = TRUE
)
# 4. Trace plots & posterior summaries
beta_chain_array <- simplify2array(res_m$beta_chain)
trace_stats      <- plot_trace_and_summary(beta_chain_array, "beta")
trace_stats
sim$beta
par(mfrow=c(1,1))
# 5. Compute model DICs
ll_chain <- sapply(res_m$w_chain,
function(W) dmnl_loglik(W, sim$Y))
W_hat   <- alr(compress_counts(sim$Y) / rowSums(sim$Y))
ll_hat  <- dmnl_loglik(W_hat, sim$Y)
dic_res <- compute_dic(ll_chain, ll_hat)
# 6. Posterior predictive simulation and Mahalanobis residuals
Y_pred_list <- lapply(seq_along(res_m$w_chain), function(i) {
sample_posterior_predictive(X = sim$X,
beta = res_m$beta_chain[[i]],
Sigma = res_m$sigma_chain[[i]],
n = sim$n,
Z = sim$Z,
psi = res_m$psi_chain[[i]],
mixed = TRUE,
verbose = FALSE
)
})
?sample_posterior_predictive
devtools::install_github("eaegerber/MMLN")
detach(MMLN)
?simulate_mixed_mln_data
